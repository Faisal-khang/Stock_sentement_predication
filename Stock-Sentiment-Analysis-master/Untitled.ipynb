{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e421d914-89d1-439f-b4f9-862c94093a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: nltk>=3.9 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from textblob) (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>=3.9->textblob) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>=3.9->textblob) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>=3.9->textblob) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob\n",
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f639c565-96b5-4125-9c9a-69cbac06f9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa52e314-33fe-4c07-821e-b0fdecdc78cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error, r2_score\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob  \u001b[38;5;66;03m# simpler sentiment scoring without extra installation\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 2. Load data\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# =============================\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Replace with your CSV file\u001b[39;00m\n\u001b[0;32m     18\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, parse_dates\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 1. Imports\n",
    "# =============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from textblob import TextBlob  # simpler sentiment scoring without extra installation\n",
    "\n",
    "# =============================\n",
    "# 2. Load data\n",
    "# =============================\n",
    "# Replace with your CSV file\n",
    "df = pd.read_csv(\"your_data.csv\", parse_dates=[\"Date\"])\n",
    "\n",
    "# =============================\n",
    "# 3. Fill missing headline values\n",
    "# =============================\n",
    "df.iloc[:,2:27] = df.iloc[:,2:27].fillna('')\n",
    "\n",
    "# =============================\n",
    "# 4. Combine Top1–Top25 into single daily text\n",
    "# =============================\n",
    "df[\"Combined_Headlines\"] = df.iloc[:,2:27].astype(str).apply(lambda x: \" \".join(x), axis=1)\n",
    "\n",
    "# =============================\n",
    "# 5. Lexicon-based sentiment scoring using TextBlob\n",
    "# =============================\n",
    "df[\"SentimentScore\"] = df[\"Combined_Headlines\"].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "\n",
    "# Optional: rolling sentiment (3-day window)\n",
    "df[\"Sentiment_Rolling3\"] = df[\"SentimentScore\"].rolling(3).mean().fillna(0)\n",
    "\n",
    "# =============================\n",
    "# 6. TF-IDF Vectorization\n",
    "# =============================\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_text = tfidf.fit_transform(df[\"Combined_Headlines\"])\n",
    "\n",
    "# =============================\n",
    "# 7. Combine TF-IDF + numeric features\n",
    "# =============================\n",
    "X_features = np.hstack([\n",
    "    X_text.toarray(),\n",
    "    df[[\"SentimentScore\", \"Sentiment_Rolling3\"]].values\n",
    "])\n",
    "\n",
    "# Target variable\n",
    "y = df[\"Sentiment\"]  # numeric outcome\n",
    "\n",
    "# =============================\n",
    "# 8. Outlier removal (Z-score method)\n",
    "# =============================\n",
    "from scipy import stats\n",
    "z_scores = stats.zscore(y)\n",
    "mask = np.abs(z_scores) < 3\n",
    "X_filtered = X_features[mask]\n",
    "y_filtered = y[mask]\n",
    "\n",
    "print(\"Removed outliers. Dataset size after filtering:\", X_filtered.shape[0])\n",
    "\n",
    "# =============================\n",
    "# 9. Train/Test Split (time-aware)\n",
    "# =============================\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_filtered, y_filtered, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# =============================\n",
    "# 10. Regression Models\n",
    "# =============================\n",
    "# Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred_lr = lr.predict(X_test)\n",
    "\n",
    "# Random Forest Regression\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "pred_rf = rf.predict(X_test)\n",
    "\n",
    "# =============================\n",
    "# 11. Evaluation\n",
    "# =============================\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{model_name} - MSE: {mse:.4f}, R²: {r2:.4f}\")\n",
    "    return mse, r2\n",
    "\n",
    "mse_lr, r2_lr = evaluate_model(y_test, pred_lr, \"Linear Regression\")\n",
    "mse_rf, r2_rf = evaluate_model(y_test, pred_rf, \"Random Forest\")\n",
    "\n",
    "# =============================\n",
    "# 12. Visualization\n",
    "# =============================\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y_test.values, label=\"Actual\")\n",
    "plt.plot(pred_lr, label=\"Linear Regression\")\n",
    "plt.plot(pred_rf, label=\"Random Forest\")\n",
    "plt.legend()\n",
    "plt.title(\"Actual vs Predicted Sentiment / Target\")\n",
    "plt.show()\n",
    "\n",
    "# =============================\n",
    "# 13. Export Results\n",
    "# =============================\n",
    "results = df.iloc[len(X_train):].copy()\n",
    "results[\"Pred_LR\"] = pred_lr\n",
    "results[\"Pred_RF\"] = pred_rf\n",
    "results.to_csv(\"sentiment_forecast_results.csv\", index=False)\n",
    "\n",
    "print(\"Pipeline complete. Results saved to 'sentiment_forecast_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e4bf2-0e83-4054-8efb-6a66eb9458b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4fe378-78f8-432e-8678-c9757bb7adcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
